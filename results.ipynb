{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"legend.edgecolor\"] = 'black'\n",
    "plt.rcParams[\"legend.fontsize\"] = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-label Roberta Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = './data'\n",
    "\n",
    "def load_data_file(path):\n",
    "    lines_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines_list.append(json.loads(line))\n",
    "\n",
    "    df = pd.DataFrame(lines_list)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    # Combine context and target\n",
    "    contexts = df['context'].values\n",
    "    targets = df['target'].values\n",
    "    df['text'] = list(map(lambda x,y: str(x) + ' [SEP] ' + str(y), contexts, targets))\n",
    "    df = df.drop(columns=['context', 'target'])\n",
    "    \n",
    "    # Cast label to int\n",
    "    df['label'] = list(map(lambda x: int(x), df['label']))\n",
    "    \n",
    "    # TODO: Binarize labels\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_gold_df = load_data_file(data_path + '/gold/train.jsonl')\n",
    "val_gold_df = load_data_file(data_path + '/gold/val.jsonl')\n",
    "test_df = load_data_file(data_path + '/gold/test.jsonl') # The test set only comes from the 'gold' category\n",
    "\n",
    "train_silver_df = load_data_file(data_path + '/silver/train.jsonl')\n",
    "val_silver_df = load_data_file(data_path + '/silver/val.jsonl')\n",
    "\n",
    "#Combine Gold and Silver\n",
    "train_df = pd.concat([train_gold_df, train_silver_df])\n",
    "val_df = pd.concat([val_gold_df, val_silver_df])\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "val_df = preprocess(val_df)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)\n",
    "\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, add_special_tokens = True)\n",
    "\n",
    "train_encoded = train_ds.map(tokenize, batched=True, batch_size=None)\n",
    "val_encoded = train_ds.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "\n",
    "model_ckpt = \"roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           num_labels=3)\n",
    "\n",
    "batch_size = 4\n",
    "logging_steps = len(train_encoded) // batch_size\n",
    "print(logging_steps)\n",
    "model_name = model_ckpt + \"-finetune\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=8,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False, \n",
    "                                  log_level=\"error\",\n",
    "                                  save_total_limit = 2)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=train_encoded,\n",
    "                  eval_dataset=val_encoded,\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()\n",
    "trainer.save_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = [\n",
    "    {\n",
    "        'loss': 1.0504,\n",
    "        'learning_rate': 1.7500000000000002e-05,\n",
    "        'eval_loss': 1.029897928237915,\n",
    "        'eval_accuracy': 0.5088,\n",
    "        'eval_f1': 0.3736653454006238,\n",
    "        'eval_runtime': 46.972,\n",
    "        'eval_samples_per_second': 106.446,\n",
    "        'eval_steps_per_second': 26.612,\n",
    "        'epoch': 1.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.9781,\n",
    "        'learning_rate': 1.5000000000000002e-05,\n",
    "        'eval_loss': 0.840813398361206,\n",
    "        'eval_accuracy': 0.6424,\n",
    "        'eval_f1': 0.56688350507592,\n",
    "        'eval_runtime': 46.818,\n",
    "        'eval_samples_per_second': 106.797,\n",
    "        'eval_steps_per_second': 26.699,\n",
    "        'epoch': 2.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.8566,\n",
    "        'learning_rate': 1.25e-05,\n",
    "        'eval_loss': 0.7092211246490479,\n",
    "        'eval_accuracy': 0.7366,\n",
    "        'eval_f1': 0.7193137582035783,\n",
    "        'eval_runtime': 46.8272,\n",
    "        'eval_samples_per_second': 106.775,\n",
    "        'eval_steps_per_second': 26.694,\n",
    "        'epoch': 3.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.7543,\n",
    "        'learning_rate': 1e-05,\n",
    "        'eval_loss': 0.5204271078109741,\n",
    "        'eval_accuracy': 0.8188,\n",
    "        'eval_f1': 0.8181573594078856,\n",
    "        'eval_runtime': 46.732,\n",
    "        'eval_samples_per_second': 106.993,\n",
    "        'eval_steps_per_second': 26.748,\n",
    "        'epoch': 4.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.6637,\n",
    "        'learning_rate': 7.500000000000001e-06,\n",
    "        'eval_loss': 0.3766619861125946,\n",
    "        'eval_accuracy': 0.8884,\n",
    "        'eval_f1': 0.8886097251146162,\n",
    "        'eval_runtime': 46.7722,\n",
    "        'eval_samples_per_second': 106.901,\n",
    "        'eval_steps_per_second': 26.725,\n",
    "        'epoch': 5.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.5568,\n",
    "        'learning_rate': 5e-06,\n",
    "        'eval_loss': 0.3678179979324341,\n",
    "        'eval_accuracy': 0.917,\n",
    "        'eval_f1': 0.9170797350619568,\n",
    "        'eval_runtime': 46.7381,\n",
    "        'eval_samples_per_second': 106.979,\n",
    "        'eval_steps_per_second': 26.745,\n",
    "        'epoch': 6.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.466,\n",
    "        'learning_rate': 2.5e-06,\n",
    "        'eval_loss': 0.2727004289627075,\n",
    "        'eval_accuracy': 0.9402,\n",
    "        'eval_f1': 0.9402160976443098,\n",
    "        'eval_runtime': 46.7837,\n",
    "        'eval_samples_per_second': 106.875,\n",
    "        'eval_steps_per_second': 26.719,\n",
    "        'epoch': 7.0\n",
    "    },\n",
    "    {\n",
    "        'loss': 0.3847,\n",
    "        'learning_rate': 0.0,\n",
    "        'eval_loss': 0.26842257380485535,\n",
    "        'eval_accuracy': 0.9464,\n",
    "        'eval_f1': 0.9462601781741261,\n",
    "        'eval_runtime': 46.7111,\n",
    "        'eval_samples_per_second': 107.041,\n",
    "        'eval_steps_per_second': 26.76,\n",
    "        'epoch': 8.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0504\n",
      "1.7500000000000002e-05\n",
      "1.029897928237915\n",
      "0.5088\n",
      "0.3736653454006238\n",
      "46.972\n",
      "106.446\n",
      "26.612\n",
      "1.0\n",
      "0.9781\n",
      "1.5000000000000002e-05\n",
      "0.840813398361206\n",
      "0.6424\n",
      "0.56688350507592\n",
      "46.818\n",
      "106.797\n",
      "26.699\n",
      "2.0\n",
      "0.8566\n",
      "1.25e-05\n",
      "0.7092211246490479\n",
      "0.7366\n",
      "0.7193137582035783\n",
      "46.8272\n",
      "106.775\n",
      "26.694\n",
      "3.0\n",
      "0.7543\n",
      "1e-05\n",
      "0.5204271078109741\n",
      "0.8188\n",
      "0.8181573594078856\n",
      "46.732\n",
      "106.993\n",
      "26.748\n",
      "4.0\n",
      "0.6637\n",
      "7.500000000000001e-06\n",
      "0.3766619861125946\n",
      "0.8884\n",
      "0.8886097251146162\n",
      "46.7722\n",
      "106.901\n",
      "26.725\n",
      "5.0\n",
      "0.5568\n",
      "5e-06\n",
      "0.3678179979324341\n",
      "0.917\n",
      "0.9170797350619568\n",
      "46.7381\n",
      "106.979\n",
      "26.745\n",
      "6.0\n",
      "0.466\n",
      "2.5e-06\n",
      "0.2727004289627075\n",
      "0.9402\n",
      "0.9402160976443098\n",
      "46.7837\n",
      "106.875\n",
      "26.719\n",
      "7.0\n",
      "0.3847\n",
      "0.0\n",
      "0.26842257380485535\n",
      "0.9464\n",
      "0.9462601781741261\n",
      "46.7111\n",
      "107.041\n",
      "26.76\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "list(logs[0].keys())\n",
    "for l in logs:\n",
    "    for key in list(l.keys()):\n",
    "        print(l[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5088, 0.6424, 0.7366, 0.8188, 0.8884, 0.917, 0.9402, 0.9464]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for k in list(logs[0].keys()):\n",
    "    result[k] = []\n",
    "\n",
    "for l in logs:\n",
    "    for k in list(l.keys()):\n",
    "        result[k].append(l[k])\n",
    "        \n",
    "result['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(result['epoch'], result['eval_accuracy'], linewidth=3)\n",
    "    \n",
    "# plt.legend(title=\"LR\")   \n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Evaluation Accuracy\")\n",
    "plt.title(\"Accuracy per Epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
